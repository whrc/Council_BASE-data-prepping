---
title: "5. from kyle_add gapfilled data"
output: html_document
date: "2024-09-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())

library(data.table)
library(ggplot2)
setwd('C:/Users/kkent/Documents/Github Flux Network/Council BASE prepping/') #use this to set your directory - Git folder
#setwd('C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/') #use this to set your directory - Council Data doc folder 

Sys.setenv(TZ='UTC')
```

#read the ungapfilled data so it can be merged with the gapfilled data 
```{r}
# dat.h =fread("C:/Users/kkent/Documents/Github Flux Network/Council BASE prepping/Council_BASE-data-prepping/data/council-Results_data_2017_2023.txt", header = T, nrows = 0) #header
# 
# dat =fread("C:/Users/kkent/Documents/Github Flux Network/Council BASE prepping/Council_BASE-data-prepping/data/council-Results_data_2017_2023.txt", header = F, skip = 2) #removes the row with the units


  
dat.h =fread("C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/data/council-Results_data_2017_2023.txt", header = T, nrows = 0) #header

dat =fread("C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council-Results_data_2017_2023.txt", header = F, skip = 2) #removes the row with the units

names (dat) = names (dat.h) #binds header and df without units together 

#dat = fread('./council_2017_2023_gf.csv')

```


#read in the gapfilled data / gapfilling output 
```{r}
gfh  = fread('C:/Users/kkent/Documents/Github Flux Network/Council BASE prepping/Council_BASE-data-prepping/data/council-Results_data_2017_2023.txt',header = T,nrows = 0) #reads in gap-filled data names  

gf   = fread('C:/Users/kkent/Documents/Github Flux Network/Council BASE prepping/Council_BASE-data-prepping/data/council-Results_data_2017_2023.txt',header = F,skip  = 2,na.strings = c('-9999','-10000','-9.9990e+03')) #adjusts for NAs

names(gf) = names(gfh)


```

#break apart the time column
```{r}
hour = floor(x = gf$Hour)
dif = gf$Hour - hour
min = dif*60
time = paste(hour,min,sep = ':')
date = paste(gf$Year,gf$DoY,sep = '-')
ts   = as.POSIXct(paste(date,time,sep = ' '),format = '%Y-%j %H:%M')
gf$ts = ts

summary(gf$ts)

hour = floor(x = dat$Hour)
dif = dat$Hour - hour
min = dif*60
time = paste(hour,min,sep = ':')
date = paste(dat$Year,dat$DoY,sep = '-')
ts   = as.POSIXct(paste(date,time,sep = ' '),format = '%Y-%j %H:%M')
dat$ts = ts

summary(dat$ts)

```

#reduce the gapfilled dataset to the variables of interest 
```{r}
gfdat = data.frame(gf$ts,
                   gf$Rg_f,
#                   gf$H_f,
#                   gf$LE_f,
#                   gf$NEE_f,
#                   gf$NEE_fall,
#                   gf$CH4_f,
#                   gf$CH4_fall,
                   gf$Tsoil_f,
                   gf$Tair_f,
                   gf$VPD_f,
                   gf$RH_f,
                   gf$Reco,
            #       gf$Reco_DT,
                   gf$GPP_f)
             #      gf$GPP_DT)

names(gfdat) = c('ts',
                 'Rg_f',
#                 'H_f',
#                 'LE_f',
#                 'NEE_f',
#                 'NEE_fall',
#                 'CH4_f',
#                 'CH4_fall',
                 'Tsoil_f',
                 'Tair_f',
                 'VPD_f',
                 'RH_f',
                 'Reco',
           #      'GPP_DT',
                 'GPP_f')
           #      'Reco_DT')
```



#merge the ungapfilled data with the gapfilled data 
```{r}

dat = merge(dat,gfdat, by = 'ts')
dat$dup = duplicated(x = dat$ts)
dat = subset(dat,dat$dup == 'FALSE')

summary(dat$ts) #check out timestamp to make sure it looks correct
```

#save as new file 
```{r}

#save to git folder in docs 
write.csv(x = dat,file = 'C:/Users/kkent/Documents/Github Flux Network/Council BASE prepping/Council_BASE-data-prepping/data/council_gapfilled_clean_2017_2023.csv',quote = F,row.names = F)

#save to council data folder in docs 
write.csv(x = dat,file = 'C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_gapfilled_clean_2017_2023.csv',quote = F,row.names = F)



```

